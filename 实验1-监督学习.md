# 《机器学习与模式识别》上机实验指导

&nbsp;
## 实验一：监督学习之分类
&nbsp;
### 1. 实验目的
* 了解Python基础知识，并安装Anaconda环境用于运行Python程序；
* 熟悉K近邻（KNN）分类原理，了解影响KNN分类结果的主要因素；
* 熟悉模型拟合中的欠拟合和过拟合现象，并可以通过调整参数进行改进。

&nbsp;
### 2. 实验内容：
* **K-近邻算法（KNN）实验**
  
    > 根据实验提供的KNN代码文件（KNN.ipynb）开展实验：
    >    - 使用jupyter或其他环境运行KNN代码；
    >    - 合理组合以下几种参数的不同值：数据集（例如iris, wine, breast cancer）、采样率（sample rate = 1, 0.5, 0.2等）和近邻范围K（K=1, 5, 10等），实验并观察各种参数组合下KNN分类算法的精度变化情况，试分析产生相关结果的原因；
    >    - <u>(选做题)</u>：改进现有代码，提高KNN算法的实现性能。例如，提高大规模训练数据下的分类速度，在保证精度的前提下增强算法的鲁棒性，提供自适应的参数选择策略等;
    >    - 实验报告：记录不同参数组合下的分类精度，绘制分类精度随参数变化的效果图，并结合实验结果给出参数选取的实验建议。对于选做题，改进内容不限，但需要进行必要的文字说明和实验效果验证。

* **基于高阶多项式回归的欠拟合和过拟合分析实验**

	> 根据实验提供的Regression代码文件（Regression.ipynb）开展实验：
    >    - 使用jupyter或其他环境运行KNN代码；
    >    - 使用jupyter或其他环境；代码功能为：使用一元M次多项式回归拟合正弦函数（最小二乘法）。数据点数固定为200个；
    >    - 合理组合以下几种参数的不同值：信号频率（1、2、4、8），噪声方差0.1、0.2、0.3、0.5，每趟实验同时观察4种阶数的多项式的拟合情况M=10、30、50、180。观察各种参数组合下多项式回归对信号与噪声的拟合程度，分析产生欠拟合和过拟合现象的一些条件；
    >    - 实验报告：记录有明显拟合效果差异的参数组合，记录参数与对应的拟合图形，说明拟合效果与条件的关系，并就如何避免模型欠拟合和过拟合提出想法。

&nbsp;
### 3. 补充说明：
* 代码中对应代码处有注释，请根据注释开展实验
* 使用最小二乘法拟合曲线[^最小二乘法]

	> [^最小二乘法]: 高斯于1823年在误差 $e_1 , \cdots, e_n$ 独立同分布的假定下,证明了最小二乘法的一个最优性质: 在所有无偏的线性估计类中,最小二乘法是其中方差最小的！
	> - 对于数据$(x_i, y_i) (i=1,2,\cdots,m)$， 拟合出函数$h(x)$，有误差，即残差：$r_i=h(x_i)-y_i$
	> - 此时L2范数（残差平方和）最小时，$h(\mathbf{x})$和$y$相似度最高，更拟合一般的$H(x)$的$n$次多项式，$H(x)=w_0+w_1x+w_2x^2+\cdots+w_nx^n$, 其中$\mathbf{w}=[w_0, w_1, \cdots, w_n]$为参数
	> - 最小二乘法就是要找到一组$\mathbf{w}=[w_0, w_1, \cdots, w_n]$，使得$\sum_{i=1}^{m}(h(x_i)-y_i)^2$(残差平方和)最小，即求$\min \sum_{i=1}^{m}(h(x_i)-y_i)$


